# Multi-Batch 2 Logic Flow Explanation

## üèóÔ∏è Architecture Overview

The script implements a **parallel multi-agent batch processing system** with three main components:

1. **AsyncTransformerAgent** - Generates SPSS scripts from survey questions
2. **AsyncReviewerAgent** - Reviews generated scripts for correctness
3. **AsyncMultiAgentPipeline** - Orchestrates the parallel batch processing

---

## üìä High-Level Execution Flow

```
main()
  ‚îî‚îÄ> asyncio.run(main_async())
       ‚îî‚îÄ> AsyncMultiAgentPipeline.run_async()
            ‚îú‚îÄ> Load training context
            ‚îú‚îÄ> Find generation files (*.md)
            ‚îî‚îÄ> Process files (sequentially or in parallel)
                 ‚îî‚îÄ> _process_file_async()
                      ‚îú‚îÄ> Parse questions from file
                      ‚îú‚îÄ> Split into batches
                      ‚îî‚îÄ> Process batches in PARALLEL chunks
                           ‚îî‚îÄ> _process_batch_async() [for each batch]
                                ‚îî‚îÄ> Feedback loop (up to MAX_FEEDBACK_LOOPS)
```

---

## üîÑ Detailed Flow Breakdown

### **Phase 1: Initialization** (`main()` ‚Üí `run_async()`)

1. **Startup Configuration**
   - Loads environment variables (batch size, model, rate limits, etc.)
   - Prints effective configuration
   - Initializes `SPSSBatchProcessor` from `main.py`

2. **Agent Initialization**
   - Creates `AsyncTransformerAgent` (uses `AsyncOpenAI` client)
   - Creates `AsyncReviewerAgent` (uses batch reviewer prompt)
   - Sets up learning memory manager (if enabled)

3. **Training Context Loading**
   - Loads training examples from `training/` directory
   - Calculates token estimates

---

### **Phase 2: File Processing** (`_process_file_async()`)

1. **Parse Generation File**
   - Reads `.md` file from `generation/` directory
   - Extracts questions from `## Sheet1` section
   - Extracts `function_def` section
   - Creates `expected_logic` dictionary (QID ‚Üí question details)

2. **Batch Creation**
   - Splits questions into batches of size `BATCH_SIZE` (default: 10)
   - Calculates number of batches: `num_batches = ceil(total_questions / BATCH_SIZE)`
   - Creates training context per batch:
     - **Batch 0**: Full training context (or trimmed to `TRAINING_CONTEXT_FIRST_BATCH_CHARS`)
     - **Other batches**: Empty or trimmed context (based on `INCLUDE_TRAINING_IN_ALL`)

3. **Parallel Batch Processing**
   - Creates async tasks for all batches
   - Groups batches into **chunks** of `MAX_PARALLEL_BATCHES` (default: 10)
   - Processes chunks sequentially, but batches within chunk run **in parallel**
   - Uses `asyncio.gather()` to execute multiple batches concurrently

```
Example: 16 batches, MAX_PARALLEL_BATCHES=10
  Chunk 1: Batches 1-10  ‚Üí Process in parallel ‚ö°
  Chunk 2: Batches 11-16 ‚Üí Process in parallel ‚ö°
```

---

### **Phase 3: Batch Processing** (`_process_batch_async()`)

Each batch goes through a **feedback loop** (up to `MAX_FEEDBACK_LOOPS` = 7):

#### **Loop 0 (First Iteration)**

1. **Pre-Analysis (Optional)**
   - If `SKIP_PRE_ANALYSIS=false`:
     - `AsyncReviewerAgent.pre_analyze_questions_async()` analyzes questions
     - Curates relevant training examples (max `PRE_ANALYSIS_MAX_CHARS` chars)
     - Caches curated context for reuse
   - If skipped: uses full training context

2. **Generation**
   - `AsyncTransformerAgent.generate_batch_async()`:
     - Formats all questions in batch
     - Builds prompt with curated/full training context
     - Injects anti-patterns and chain-of-thought (if enabled)
     - Calls OpenAI API (async) with rate limiting
     - Parses output to extract SPSS scripts per question
   - Returns: `Dict[QID ‚Üí SPSS_script]`

3. **Review**
   - `AsyncReviewerAgent.review_batch_async()`:
     - Reviews **ALL questions in batch in ONE API call** (batch review)
     - Compares generated scripts against expected logic
     - Returns findings: `List[Dict]` with `pass`, `root_causes`, `instructions`

4. **Result Collection**
   - Passing questions ‚Üí added to `batch_outputs`
   - Failing questions ‚Üí kept in `remaining_questions` for next loop

#### **Loop 1+ (Feedback Loops)**

1. **Learning Memory Integration**
   - Records failures in learning memory (question type ‚Üí failure pattern)
   - Retrieves relevant lessons for question types

2. **Regeneration**
   - `AsyncTransformerAgent.regenerate_subset_async()`:
     - Takes only failed questions
     - Includes reviewer feedback (root causes + instructions)
     - Uses **progressive context reduction** (reduces training context in later loops)
     - Calls OpenAI API with feedback
     - Returns regenerated scripts

3. **Review Again**
   - Reviews regenerated scripts
   - Collects passing/failing results

4. **Loop Termination**
   - If all questions pass ‚Üí return `batch_outputs`
   - If max loops reached ‚Üí return passing + failed questions
   - Otherwise ‚Üí continue to next loop

---

### **Phase 4: Rate Limiting & Concurrency Control**

**Global Rate Limiter** (`GlobalRateLimiter`):
- Uses `asyncio.Semaphore` to limit concurrent API calls (`MAX_CONCURRENT_REQUESTS` = 5)
- Implements dynamic delay adjustment based on error rates
- Adds random jitter to avoid "thundering herd" effect

**Flow:**
```
API Call Request
  ‚îî‚îÄ> rate_limiter.acquire()  [waits if semaphore full]
       ‚îî‚îÄ> Make API call
            ‚îî‚îÄ> rate_limiter.release()
```

**Parallel Processing Control:**
- Batches processed in chunks of `MAX_PARALLEL_BATCHES`
- Within chunk: batches run concurrently
- Between chunks: sequential (waits for chunk to complete)

---

## üéØ Key Features & Enhancements

### **1. Parallel Batch Processing**
- Multiple batches processed simultaneously
- Controlled concurrency via chunking
- Significantly faster than sequential processing

### **2. Batch Review Optimization**
- Reviews all questions in batch in **one API call** (not one-by-one)
- Reduces API calls from N to 1 per batch

### **3. Learning Memory**
- Tracks common failure patterns
- Records successful fixes
- Provides lessons for similar question types

### **4. Progressive Context Reduction**
- Reduces training context size in later feedback loops
- Focuses on relevant examples based on failures
- Saves tokens and improves speed

### **5. Smart Retries**
- Enhanced feedback with root causes and specific instructions
- Anti-patterns injection to avoid common mistakes
- Chain-of-thought reasoning (optional)

### **6. Pre-Analysis Caching**
- First batch: pre-analyzes and curates training context
- Cached curated context reused for subsequent batches
- Saves API calls and time

---

## üìà Example Execution Flow

**Scenario:** File with 156 questions, BATCH_SIZE=10, MAX_PARALLEL_BATCHES=10

```
1. Parse file ‚Üí 156 questions
2. Split into 16 batches (10 questions each)
3. Process in 2 chunks:
   
   Chunk 1 (Batches 1-10):
     Batch 1: Loop 0 ‚Üí Generate ‚Üí Review ‚Üí 8 pass, 2 fail
              Loop 1 ‚Üí Regenerate 2 ‚Üí Review ‚Üí 2 pass ‚úÖ
     Batch 2: Loop 0 ‚Üí Generate ‚Üí Review ‚Üí 10 pass ‚úÖ
     ...
     Batch 10: [parallel processing]
   
   Chunk 2 (Batches 11-16):
     Batch 11-16: [parallel processing]

4. Collect all passing outputs
5. Write to output/SPSS_output_*.sps
```

**Total API Calls (approximate):**
- Pre-analysis: 1 per file (cached)
- Generation: 16 batches √ó ~1-2 loops = 16-32 calls
- Review: 16 batches √ó ~1-2 loops = 16-32 calls
- **Total: ~33-65 calls** (vs ~312+ for sequential one-by-one)

---

## üîß Configuration Points

**Key Environment Variables:**
- `BATCH_SIZE`: Questions per batch (default: 10)
- `MAX_PARALLEL_BATCHES`: Batches processed simultaneously (default: 10)
- `MAX_FEEDBACK_LOOPS`: Max retry loops per batch (default: 7)
- `MAX_CONCURRENT_REQUESTS`: Concurrent API calls (default: 5)
- `SKIP_PRE_ANALYSIS`: Skip pre-analysis for speed (default: false)
- `ENABLE_LEARNING_MEMORY`: Track failures/successes (default: true)

---

## üé® Data Structures

**Key Data Flow:**
```
questions: List[Dict] ‚Üí Batch ‚Üí Dict[QID, SPSS_script] ‚Üí Review ‚Üí List[Finding]
                                                                    ‚Üì
                                                          {pass: bool, root_causes: [], instructions: []}
```

**Finding Structure:**
```python
{
    "question_id": "Q1",
    "pass": False,
    "root_causes": ["Missing entry condition check"],
    "instructions": ["Apply screener condition before validation"]
}
```

---

## üöÄ Performance Optimizations

1. **Parallel Processing**: 10x speedup for large files
2. **Batch Review**: Reduces API calls by ~90%
3. **Context Caching**: Reuses curated context across batches
4. **Progressive Reduction**: Saves tokens in later loops
5. **Smart Rate Limiting**: Adapts to API performance

---

## üìù Output Files

1. **SPSS Scripts**: `output/SPSS_output_{filename}.sps`
2. **Review Reports**: `output/review_reports/processed_{filename}_batch_{N}_loop_{M}.jsonl`
3. **Learning Memory**: `learning_memory.json` (if enabled)

---

This architecture enables **fast, parallel, intelligent** processing of large survey question files with automatic error correction through multi-agent feedback loops.

